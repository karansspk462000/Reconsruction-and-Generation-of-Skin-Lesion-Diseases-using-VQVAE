{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_root_dir, sketch_root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.image_root_dir = image_root_dir\n",
    "        self.sketch_root_dir = sketch_root_dir\n",
    "        self.transform = transform\n",
    "        self.num_sketches = 3594  # Update with the actual number of sketches\n",
    "        self.num_samples = len(self.data_frame)\n",
    "\n",
    "        # Compute variance of the data\n",
    "        # self.variance = self.compute_variance().to(device)\n",
    "\n",
    "    def compute_variance(self):\n",
    "        # Load all images and compute variance\n",
    "        data = []\n",
    "        for idx in tqdm(range(len(self))):\n",
    "            img_name = os.path.join(self.image_root_dir, self.data_frame.iloc[idx, 0] + '.jpg')\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            data.append(image.numpy())\n",
    "\n",
    "        data = np.array(data)\n",
    "        data = torch.from_numpy(data).to(device)\n",
    "        return torch.var(data / 255.0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_root_dir, self.data_frame.iloc[idx, 0] + '.jpg')\n",
    "        sketch_idx = idx % self.num_sketches  # Cyclic indexing for sketches\n",
    "        sketch_name = os.path.join(self.sketch_root_dir, f\"sketch_{sketch_idx + 1}.png\")\n",
    "        \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        sketch = Image.open(sketch_name).convert('RGB')\n",
    "\n",
    "        label = torch.tensor(self.data_frame.iloc[idx, 1:], dtype=torch.float32)\n",
    "\n",
    "        rand_idx = random.randint(0, self.num_samples - 1)\n",
    "        rand_label = torch.tensor(self.data_frame.iloc[rand_idx, 1:], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            sketch = self.transform(sketch)\n",
    "        \n",
    "        return label, sketch, image, img_name, rand_label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    # transforms.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),\n",
    "#     transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "#     transforms.RandomRotation(15),  # Randomly rotate the image up to 15 degrees\n",
    "#     # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "#     transforms.RandomGrayscale(p=0.1),  # Randomly convert images to grayscale with a probability of 0.1\n",
    "#     transforms.ToTensor(),\n",
    "#     # transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.333)),  # Randomly crop the image and resize it to 256x256\n",
    "#     # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "# ])\n",
    "\n",
    "\n",
    "train_dataset = SketchDataset(csv_file='/home/cvlab/Karan/A_3/Dataset_A4/Train_labels.csv', \n",
    "                              image_root_dir='/home/cvlab/Karan/A_3/Dataset_A4/Train_data',\n",
    "                              sketch_root_dir='/home/cvlab/Karan/A_3/Dataset_A4/Unpaired_sketch',\n",
    "                              transform=transform)\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_images(dataloader, num_images=5):\n",
    "    # Get a batch of data\n",
    "    data_iterator = iter(dataloader)\n",
    "    _, _, images, _, _ = next(data_iterator)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(8, 6))\n",
    "    for i in range(num_images):\n",
    "        image = images[i].permute(1, 2, 0)  # Change tensor shape to (H, W, C) for plotting\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display images\n",
    "show_images(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PixelConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PixelConvLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.pixel_conv_layer = PixelConvLayer(in_channels=128, out_channels=256)\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            ResidualBlock(channels=256),\n",
    "            ResidualBlock(channels=256),\n",
    "            ResidualBlock(channels=256),\n",
    "            ResidualBlock(channels=256),\n",
    "            ResidualBlock(channels=256)\n",
    "        )\n",
    "        self.pixel_conv_layer_6 = PixelConvLayer(in_channels=256, out_channels=128)\n",
    "        self.pixel_conv_layer_7 = PixelConvLayer(in_channels=128, out_channels=128)\n",
    "        self.conv2d_18 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pixel_conv_layer(x)\n",
    "        out = self.residual_blocks(out)\n",
    "        out = self.pixel_conv_layer_6(out)\n",
    "        out = self.pixel_conv_layer_7(out)\n",
    "        out = self.conv2d_18(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch import distributed as dist_fn\n",
    "import wandb\n",
    "\n",
    "class Quantize(nn.Module):\n",
    "    def __init__(self, dim, n_embed, decay=0.99, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.n_embed = n_embed\n",
    "        self.decay = decay\n",
    "        self.eps = eps\n",
    "\n",
    "        embed = torch.randn(dim, n_embed)\n",
    "        self.register_buffer(\"embed\", embed)\n",
    "        self.register_buffer(\"cluster_size\", torch.zeros(n_embed))\n",
    "        self.register_buffer(\"embed_avg\", embed.clone())\n",
    "\n",
    "    def forward(self, input):\n",
    "        flatten = input.reshape(-1, self.dim)\n",
    "        dist = (\n",
    "            flatten.pow(2).sum(1, keepdim=True)\n",
    "            - 2 * flatten @ self.embed\n",
    "            + self.embed.pow(2).sum(0, keepdim=True)\n",
    "        )\n",
    "        _, embed_ind = (-dist).max(1)\n",
    "        embed_onehot = F.one_hot(embed_ind, self.n_embed).type(flatten.dtype)\n",
    "        embed_ind = embed_ind.view(*input.shape[:-1])\n",
    "        quantize = self.embed_code(embed_ind)\n",
    "\n",
    "        if self.training:\n",
    "            embed_onehot_sum = embed_onehot.sum(0)\n",
    "            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n",
    "\n",
    "            # dist_fn.all_reduce(embed_onehot_sum)\n",
    "            # dist_fn.all_reduce(embed_sum)\n",
    "\n",
    "            self.cluster_size.data.mul_(self.decay).add_(\n",
    "                embed_onehot_sum, alpha=1 - self.decay\n",
    "            )\n",
    "            self.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)\n",
    "            n = self.cluster_size.sum()\n",
    "            cluster_size = (\n",
    "                (self.cluster_size + self.eps) / (n + self.n_embed * self.eps) * n\n",
    "            )\n",
    "            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n",
    "            self.embed.data.copy_(embed_normalized)\n",
    "\n",
    "        # diff = (quantize.detach() - input).pow(2).mean()\n",
    "        diff = (quantize - input).pow(2).mean()\n",
    "        # quantize = input + (quantize - input).detach()\n",
    "        quantize = input + (quantize - input)\n",
    "\n",
    "        return quantize, diff, embed_ind\n",
    "\n",
    "    def embed_code(self, embed_id):\n",
    "        return F.embedding(embed_id, self.embed.transpose(0, 1))\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channel, channel, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel, in_channel, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        out += input\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channel, channel, n_res_block, n_res_channel, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channel, out_channel, channel, n_res_block, n_res_channel, stride\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = [nn.Conv2d(in_channel, channel, 3, padding=1)]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks.extend(\n",
    "                [\n",
    "                    nn.ConvTranspose2d(channel, channel // 2, 4, stride=2, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(\n",
    "                        channel // 2, out_channel, 4, stride=2, padding=1\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks.append(\n",
    "                nn.ConvTranspose2d(channel, out_channel, 4, stride=2, padding=1)\n",
    "            )\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)\n",
    "\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=3,\n",
    "        channel=128,\n",
    "        n_res_block=2,\n",
    "        n_res_channel=32,\n",
    "        embed_dim=64,\n",
    "        n_embed=512,\n",
    "        decay=0.99,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_b = Encoder(in_channel, channel, n_res_block, n_res_channel, stride=4)\n",
    "        self.enc_t = Encoder(channel, channel, n_res_block, n_res_channel, stride=2)\n",
    "        self.quantize_conv_t = nn.Conv2d(channel, embed_dim, 1)\n",
    "        self.quantize_t = Quantize(embed_dim, n_embed)\n",
    "        self.pixelcnn=PixelCNN()\n",
    "        self.dec_t = Decoder(\n",
    "            embed_dim, embed_dim, channel, n_res_block, n_res_channel, stride=2\n",
    "        )\n",
    "        self.quantize_conv_b = nn.Conv2d(embed_dim + channel, embed_dim, 1)\n",
    "        self.quantize_b = Quantize(embed_dim, n_embed)\n",
    "        self.upsample_t = nn.ConvTranspose2d(\n",
    "            embed_dim, embed_dim, 4, stride=2, padding=1\n",
    "        )\n",
    "        self.dec = Decoder(\n",
    "            embed_dim + embed_dim,\n",
    "            in_channel,\n",
    "            channel,\n",
    "            n_res_block,\n",
    "            n_res_channel,\n",
    "            stride=4,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_t, quant_b, diff, _, _ = self.encode(input)\n",
    "\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return dec, diff\n",
    "\n",
    "    def encode(self, input):\n",
    "        enc_b = self.enc_b(input)\n",
    "        enc_t = self.enc_t(enc_b)\n",
    "\n",
    "        quant_t = self.quantize_conv_t(enc_t).permute(0, 2, 3, 1)\n",
    "        quant_t, diff_t, id_t = self.quantize_t(quant_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        diff_t = diff_t.unsqueeze(0)\n",
    "\n",
    "        dec_t = self.dec_t(quant_t)\n",
    "        enc_b = torch.cat([dec_t, enc_b], 1)\n",
    "\n",
    "        quant_b = self.quantize_conv_b(enc_b).permute(0, 2, 3, 1)\n",
    "        quant_b, diff_b, id_b = self.quantize_b(quant_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "        diff_b = diff_b.unsqueeze(0)\n",
    "\n",
    "        return quant_t, quant_b, diff_t + diff_b, id_t, id_b\n",
    "\n",
    "    def decode(self, quant_t, quant_b):\n",
    "        upsample_t = self.upsample_t(quant_t)\n",
    "        quant = torch.cat([upsample_t, quant_b], 1)\n",
    "        # print(\"quant shape: \",quant.shape)\n",
    "        quant = self.pixelcnn(quant)\n",
    "        dec = self.dec(quant)\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def decode_code(self, code_t, code_b):\n",
    "        quant_t = self.quantize_t.embed_code(code_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        quant_b = self.quantize_b.embed_code(code_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/cvlab/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin 6e1118f48554030c79713c59e8803762b6025f7f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm22rm003\u001b[0m (\u001b[33mm22rm003_kb\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/cvlab/EXT_HARD_DRIVE1/Karan/A5/wandb/run-20240501_214900-sc1imbho</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn/runs/sc1imbho' target=\"_blank\">fluent-star-3</a></strong> to <a href='https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn' target=\"_blank\">https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn/runs/sc1imbho' target=\"_blank\">https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn/runs/sc1imbho</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/m22rm003_kb/vq_vae_mask_git%2Bpixel%20cnn/runs/sc1imbho?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f435a1aa970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"vq_vae_mask_git+pixel cnn\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"architecture\": \"VQVAE\",\n",
    "    \"dataset\": \"ISIC\",\n",
    "    \"epochs\": 30,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributed as dist\n",
    "from torchvision import datasets, transforms, utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "checkpoint_dir = \"checkpoint_vqvaepixel\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "# Create the directory if it doesn't exist\n",
    "save_dir = 'vqvaepluspixel'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def train(epoch, loader, model, optimizer, device):\n",
    "  \n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    latent_loss_weight = 0.25\n",
    "    sample_size = 25\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    mse_sum = 0\n",
    "    mse_n = 0\n",
    "\n",
    "    for i, (label, sketch, img, img_name, rand_label) in tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "        sketch = sketch.to(device)\n",
    "\n",
    "        out, latent_loss = model(img)\n",
    "        recon_loss = criterion(out, img)\n",
    "        latent_loss = latent_loss.mean()\n",
    "        # print(\"latent_loss: \",latent_loss)\n",
    "        # print(\"recon_loss: \",recon_loss)\n",
    "        loss = recon_loss + latent_loss_weight * latent_loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        # \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # if scheduler is not None:\n",
    "        #     scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        # part_mse_sum = recon_loss.item() * img.shape[0]\n",
    "        # part_mse_n = img.shape[0]\n",
    "        # comm = {\"mse_sum\": part_mse_sum, \"mse_n\": part_mse_n}\n",
    "        # # comm = dist.all_gather(comm)\n",
    "\n",
    "        # for part in comm:\n",
    "        #     mse_sum += part[\"mse_sum\"]\n",
    "        #     mse_n += part[\"mse_n\"]\n",
    "        part_mse_sum = recon_loss.item() * img.shape[0]\n",
    "        part_mse_n = img.shape[0]\n",
    "        comm = {\"mse_sum\": part_mse_sum, \"mse_n\": part_mse_n}\n",
    "        # comm = dist.all_gather(comm)\n",
    "\n",
    "        for key, value in comm.items():  # Use .items() to iterate over key-value pairs\n",
    "            if key == \"mse_sum\":\n",
    "                mse_sum += value\n",
    "            elif key == \"mse_n\":\n",
    "                mse_n += value\n",
    "\n",
    "        # if dist.is_primary():\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "      \n",
    "\n",
    "        if i % 100 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            sample = img[:sample_size]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out, _ = model(sample)\n",
    "\n",
    "            utils.save_image(\n",
    "                torch.cat([sample, out], 0),\n",
    "                f\"vqvaepluspixel/{str(epoch + 1).zfill(5)}_{str(i).zfill(5)}.png\",\n",
    "                nrow=sample_size,\n",
    "                normalize=True,\n",
    "                range=(-1, 1),\n",
    "            )\n",
    "        avg_train_loss = epoch_train_loss / len(dataloader)\n",
    "        model.train()\n",
    "\n",
    "    wandb.log({\n",
    "    \"epoch\": epoch + 1,\n",
    "    \"loss\" : avg_train_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, pi, floor, sin\n",
    "\n",
    "class Phase:\n",
    "    def __init__(self, start, end, n_iter, anneal_fn):\n",
    "        self.start, self.end = start, end\n",
    "        self.n_iter = n_iter\n",
    "        self.anneal_fn = anneal_fn\n",
    "        self.n = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "\n",
    "        return self.anneal_fn(self.start, self.end, self.n / self.n_iter)\n",
    "\n",
    "    def reset(self):\n",
    "        self.n = 0\n",
    "\n",
    "    @property\n",
    "    def is_done(self):\n",
    "        return self.n >= self.n_iter\n",
    "    \n",
    "class CycleScheduler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer,\n",
    "        lr_max,\n",
    "        n_iter,\n",
    "        momentum=(0.95, 0.85),\n",
    "        divider=25,\n",
    "        warmup_proportion=0.3,\n",
    "        phase=('linear', 'cos'),\n",
    "    ):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        phase1 = int(n_iter * warmup_proportion)\n",
    "        phase2 = n_iter - phase1\n",
    "        lr_min = lr_max / divider\n",
    "\n",
    "        phase_map = {'linear': self.anneal_linear, 'cos': self.anneal_cos}\n",
    "\n",
    "        self.lr_phase = [\n",
    "            Phase(lr_min, lr_max, phase1, phase_map[phase[0]]),\n",
    "            Phase(lr_max, lr_min / 1e4, phase2, phase_map[phase[1]]),\n",
    "        ]\n",
    "\n",
    "        self.momentum = momentum\n",
    "\n",
    "        if momentum is not None:\n",
    "            mom1, mom2 = momentum\n",
    "            self.momentum_phase = [\n",
    "                Phase(mom1, mom2, phase1, phase_map[phase[0]]),\n",
    "                Phase(mom2, mom1, phase2, phase_map[phase[1]]),\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            self.momentum_phase = []\n",
    "\n",
    "        self.phase = 0\n",
    "\n",
    "    def anneal_linear(start, end, proportion):\n",
    "        return start + proportion * (end - start)\n",
    "\n",
    "\n",
    "    def anneal_cos(start, end, proportion):\n",
    "        cos_val = cos(pi * proportion) + 1\n",
    "\n",
    "    def step(self):\n",
    "        lr = self.lr_phase[self.phase].step()\n",
    "\n",
    "        if self.momentum is not None:\n",
    "            momentum = self.momentum_phase[self.phase].step()\n",
    "\n",
    "        else:\n",
    "            momentum = None\n",
    "\n",
    "        for group in self.optimizer.param_groups:\n",
    "            group['lr'] = lr\n",
    "\n",
    "            if self.momentum is not None:\n",
    "                if 'betas' in group:\n",
    "                    group['betas'] = (momentum, group['betas'][1])\n",
    "\n",
    "                else:\n",
    "                    group['momentum'] = momentum\n",
    "\n",
    "        if self.lr_phase[self.phase].is_done:\n",
    "            self.phase += 1\n",
    "\n",
    "        if self.phase >= len(self.lr_phase):\n",
    "            for phase in self.lr_phase:\n",
    "                phase.reset()\n",
    "\n",
    "            for phase in self.momentum_phase:\n",
    "                phase.reset()\n",
    "\n",
    "            self.phase = 0\n",
    "\n",
    "        return lr, momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [10:50<00:00,  2.31s/it]\n",
      "100%|██████████| 282/282 [10:31<00:00,  2.24s/it]\n",
      "100%|██████████| 282/282 [11:59<00:00,  2.55s/it]\n",
      "100%|██████████| 282/282 [12:16<00:00,  2.61s/it]\n",
      "100%|██████████| 282/282 [12:09<00:00,  2.59s/it]\n",
      "100%|██████████| 282/282 [12:16<00:00,  2.61s/it]\n",
      " 95%|█████████▌| 268/282 [10:31<00:33,  2.41s/it]"
     ]
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "epoch = 25\n",
    "\n",
    "model = VQVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "checkpoint = torch.load(\"/media/cvlab/EXT_HARD_DRIVE1/Karan/A5/checkpoint_final_code/vqvae_030.pt\")\n",
    "# model.eval()  # Set VQVAE model to evaluation mode\n",
    "\n",
    "# vqvae_state_dict = torch.load(checkpoint)\n",
    "vqvae_state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint\n",
    "\n",
    "\n",
    "# Load the state_dict to the PixelCNN model\n",
    "model.load_state_dict(vqvae_state_dict, strict=False)  # strict=False allows for loading partial state_dicts\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze VQVAE parameters\n",
    "\n",
    "# scheduler = CycleScheduler(\n",
    "#             optimizer,\n",
    "#             lr,\n",
    "#             n_iter=len(dataloader) * epoch,\n",
    "#             momentum=None,\n",
    "#             warmup_proportion=0.05,)\n",
    "\n",
    "for i in range(epoch):\n",
    "    train(i, dataloader, model, optimizer,device)\n",
    "\n",
    "    # if dist.is_primary():\n",
    "    torch.save(model.state_dict(), f\"{checkpoint_dir}/{str(i + 1).zfill(3)}.pt\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SketchDataset(csv_file='/home/cvlab/Karan/A_3/Dataset_A4/Test_data/Test_labels.csv', \n",
    "                              image_root_dir='/home/cvlab/Karan/A_3/Dataset_A4/Test_data/Test_images',\n",
    "                              sketch_root_dir='/home/cvlab/Karan/A_3/Dataset_A4/Test_data/Unpaired_test_sketch',\n",
    "                              transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "model = VQVAE().to(device)\n",
    "model.load_state_dict(torch.load('/media/cvlab/EXT_HARD_DRIVE1/Karan/A5/checkpoint_vqvaepixel_100.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Define a directory to save the images\n",
    "output_dir = \"vqvae_pixel_output_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Step 3: Test the model\n",
    "for i, (label, sketch, img, img_name, rand_label) in enumerate(test_dataloader):\n",
    "    # Assuming each batch contains input images\n",
    "   \n",
    "    img= img.to(device)\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        output_images, latent_loss = model(img)\n",
    "     \n",
    "    \n",
    "    # Concatenate input ground truth images and generated images\n",
    "    concatenated_images = torch.cat([img, output_images], dim=0)\n",
    "\n",
    "    # Save the concatenated images\n",
    "    save_image(concatenated_images, \n",
    "               os.path.join(output_dir, f\"batch_{i}.png\"),\n",
    "               nrow=img.shape[0],  # Assuming batch size is the number of images in a row\n",
    "               normalize=True, \n",
    "               range=(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
